---
title: "Example of data analyis and tree Aggregation"
author: 
- name: Ruizhu HUANG
  affiliation: 
  - Institute of Molecular Life Sciences, University of Zurich.
  - SIB Swiss Institute of Bioinformatics.
- name: Charlotte Soneson
  affiliation: 
  - Institute of Molecular Life Sciences, University of Zurich.
  - SIB Swiss Institute of Bioinformatics.
- name: Mark Robinson
  affiliation: 
  - Institute of Molecular Life Sciences, University of Zurich.
  - SIB Swiss Institute of Bioinformatics.
package: treeAGG
output: 
  BiocStyle::html_document
vignette: >
  %\VignetteIndexEntry{Tree Aggregation}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
bibliography: treeAGG_vignette.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

# Introduction

The arrangement of hypotheses in a hierarchical structure appears in many
research fields and often indicates different resolutions at which data can be
viewed. On which resolution level should the signal be intepreted has arisen
researchers' interest but is tricky to decide. For example, in the analysis of
microbial data, people are interested to detect microbial species that have
differential abundances under different phenotypic outcome. The abundance change
on the  OTU (operational taxonomic unit) level might be ignored due to the low
count. However, it might become evident on a cluster level if there is
coordinate change in the cluster of OTUs. Another example is about the oncology
study. Cell types, which are tumor associated (such as, their abundance changed
or cell state changed under different health status), are of interest. The
difficulty arises on which cluster level of the OTUs or cell types should we
investigate the association, and how should we pinpoint the cluster level that
drives this association. Currently, as we known there are methods available for
the former one but few for the later one. Our package is designed to target the
later one.


# Methods {#flowchart}

## The main structure of the pipeline provided in `r Biocpkg("treeAGG")`
```{r flowchart, echo=FALSE, fig.cap= "The workflow of treeAGG package."}
knitr::include_graphics("Flowchart.png")
```

In package `r Biocpkg("treeAGG")`, we provide a easy-to-use pipeline as shown in
Figure \@ref(fig:flowchart) to accomplish the work of data analysis and tree
aggregation. Users could take the standard 5 steps to get the final result. Or,
they could extract the table from the `assays` of the `treeSummarizedExperiment`
object after step 2 to do customized analysis, and further integrate the result
back to the main branch to perform tree aggregation on step 4. The table
extracted after step 2 has more rows than the original table because it includes
data for entities corresponding to the internal nodes of the tree. In each step,
we have listed the available functions to do it in blue texts. The details about
each steps are summarized as below.

* Step 1: Data preparation. Store data on the level of leaf nodes in a
`leafSummarizedExperiment` container. More details about the construction of a
`leafSummarizedExperiment` object could be found in the [Introduction to
leafSummarizedExperiment and treeSummarizedExperiment](Introduction to
leafSummarizedExperiment and treeSummarizedExperiment_copy.Rmd).

* Step 2: Data preparation. Derive data on the level of internal nodes and store
data on all nodes in a `treeSummarizedExperiment` contrainer. More details about
the construction of a `treeSummarizedExperiment` object could be found in the
[Introduction to leafSummarizedExperiment and
treeSummarizedExperiment](Introduction to leafSummarizedExperiment and
treeSummarizedExperiment_copy.Rmd).

* Step 3: Data analysis. User could use the available wrapper function
`runEdgeR` in our package or other suitable softwares to do customized analysis.
Test all hypotheses at tree leaves and internal nodes simultaneously and use
Benjamin-Hochberg procedure to control the FDR rate. Finally, two values, p
vlaue and adjusted p value, are required at each node to do tree aggregation.

* Step 4: Tree aggregation. Start from the leaf nodes of the tree. Compare p
values on leaf nodes to that on their parent node. If the minimum value is on
the parent node, take the parent node; otherwise, take the leaf nodes and
compare them to nodes on a higher level. Here, we refer the root node as the
highest level. Repeat the comparision until reach the root. Check the nodes
finally left and keep only those null hypothesis are rejected.

We suggest users to come back to this workflow (Figure \@ref(fig:flowchart))
after they read Section \@ref(analysis) and Section \@ref(aggregation).

## Theoretical example

Here, we shown the example of using `r Biocpkg("edgeR")` to explain how this
pipeline works. Users are free to choose any suitable packages or software to do
the analysis. Consider the case in which a table and a hiearchical structure of
$n$ entities (e.g. microbial species or cell types) are available. In table,
each row represents an entity $g$, and each column a sample. Samples are
collected from subjects with different phenotypic outcome (e.g., healthy and
diseased). Let $Y_{gi}$ denote the observed value of an entity (corresponding to
a node on the tree) $g$ in sample $i$. As assumed in `r Biocpkg("edgeR")`
[@Robinson2009], $Y_{gi}$ follows a negative binomial distribution

$$\mathbf{Y}_{gi}  \sim NB(\mathbf{M}_{i}\mathbf{p}_{gj}, \mathbf{\phi}_{g})  $$
$$g = 1, 2, 3, ..., n, n+1, ..., n+K;$$ 
$$i = 1, 2, ... m;$$ 
$$j = 1, 2, ..., J.$$


Here,  $\mathbf{M}_{i}$ is the effective total count of sample $i$,
$\mathbf{p}_{gj}$ is the relative abundance of entity $g$ with phenotypic
outcome $j$ to which sample $i$ belongs, and $\mathbf{\phi}_{g}$ is the
dispersion parameter used to consider the biological variation between samples.
The negative binomial distribution is parameterized with mean as
$\mathbb{E}[\mathbf{Y}_{gi}] = \mu_{gi} =  \mathbf{M}_{i}\mathbf{p}_{gj}$, and
variance as $\text{Var}[\mathbf{Y}_{gi}] = \mu_{gi}(1+\mu_{gi}\phi_{g})$. When
$\mathbf{\phi}_{g} = 0$, the negative binomial distribution reduces to Poisson
distribution. In total, we have $n+K$ entities, $m$ samples and $J$ conditions.
Among $n+K$ entities, $1, 2, ..., n$ correspond to the leaf nodes of the tree,
and the other $K$ entities to the internal nodes. In most case, only the former
could be observed and data analysis is hence performed only on the level of leaf
nodes. Here, we suggest to derive data for the later based on the former and
further perform analysis on all nodes of the tree. This could make it possible
to do the association investigation on all levels of the tree structure. Users
could choose a reasonable method to generate data for the entities corresponding
to internal nodes. Here, we create the abundance of an internal node by summing
the abundance of its descendant leaf nodes.


With the data ready, we could firstly estimate the the value of
$\mathbf{\phi}_{g}$ and build a generalized linear model at each node of the
tree.

$$
\text{log}(\mu_{gi}) = \mathbf{x}^{T}_{i} \mathbf{\beta}_{g}, \quad g = 1, 2, ..., n, n+1, ...., n+K
$$
where $\mathbf{x}^{T}_{i}$ is a vector of covariates including confounders
(e.g., age, gender) and the covariate of interest (e.g., diseased and healthy
sample) applied on sample $i$, and $\mathbf{\beta}_{g}$ is a vector of
corresponding regression coefficients. Let $\beta^{1}_{g}$ denote the
coefficient value for the covariate of interest in $\beta_{g}$. We then arrange
the hypotheses in a tree-like structure and test hypotheses to get a p value at
each node.
$$
H^{g}_{0}: \beta^{1}_{g} = 0 \quad  (g = 1, 2, ..., n, n+1, ...., n+K ),
$$
where n is the number of leaf nodes and K is the number of internal nodes.

Multiple testing correction method, such as Benjamin-Hochberg, could be applied
here to decide whether the null hypothesis at a node should be rejected.

It's likely that an internal node found to be significantly associated with the
phenotypic outcome is due to some of its descendant nodes. In other words, only some of its descendant nodes are phenotyic outcome associated and this signal is not diluted enough by other descendant nodes that are not phenotyic outcome associated. In tree aggregation step, we aim to pinpoint the nodes that drive the association. 

To do tree aggregation, we need the p value gained from the analysis above at each node. The algorithm starts from the leaf nodes of the tree. 

1. The p values on leaf nodes are compared with that on their parent node. If
the minimum value is on the parent node, select the parent node; otherwise,
select the leaf nodes.
2. Compare the selected nodes to nodes on a higher level as previous step. Here,
we refer the root node as the highest level.
3. Repeat the comparision until reach the root. 
4. Check the nodes finally left and keep only those null hypothesis are
rejected.

# Data preparation

Load the packages below before the start of analysis.  
```{r}
suppressPackageStartupMessages(library(treeAGG))
suppressPackageStartupMessages(library(edgeR))
suppressPackageStartupMessages(library(S4Vectors))
suppressPackageStartupMessages(library(ggtree))
```
The data analysis includes two steps. One is to do the differential abundance (DA) or differential state (DS) test, the other is to combine with the tree structure to do tree aggregation. Our package `r Biocpkg("treeAGG")` provides functions to do the second step, and users are free to perform their testing using any suitable software. Here, as an example, we show you the DA test step with `r Biocpkg("edgeR")` pacakge. `r Biocpkg("S4Vectors")` might be required in data preparation step to create `DataFrame` object.

A count table and a tree structure are required to do data analysis. If the tree structure is not a `phylo` object, we need to convert it via `as.phylo` from `r CRANpkg("ape")`.

```{r}
# count table
data("cytofCount")
count <- DataFrame(cytofCount)

# tree structure
data("cytofTree")
class(cytofTree)

# convert to the phylo class
library(ape)
Tree <- as.phylo(cytofTree)

```

The information of each cell cluster, corresponding to a row in the count table, is given in the `cytof_cluster` (see `?cytof_cluster` for more details). 
```{r}
# row information 
# add a column called nodeLab to tell which node a row corresponds to.
data("cytof_cluster")
cytof_cluster <- DataFrame(cytof_cluster)
cytof_cluster$nodeLab <- cytof_cluster$cluster
```
We add a new column named as `nodeLab` to tell which node of the tree a row of the count table corresponds to. If such a column is not given, the rownames of the `cytofCluster` is used for the mapping. Hence, users should be careful about the `nodeLab` column or the rownames, and make sure they use the same label as the node label of the tree. When the `nodeLab` column and the rownames both exist and are different, the `nodeLab` column is used.

The information of each cell cluster, corresponding to a row in the count table, is given in the `cytof_sample` (see `?cytof_sample` for more details). 
```{r}
# provide sample information: from healthy or CN group
data("cytof_sample")
```

We could organize the above data into a `leafSummarizedExperiment` object via `leafSummarizedExperiment` constructor function. See details about the class `leafSummarizedExperiment` (`?'leafSummarizedExperiment-class'`) and its constructor.
```{r}
# construct a leafSummarizedExperiment object to include tree structure, count,
# cluster information and sample information
lse <- leafSummarizedExperiment(tree = Tree,
                                assays = list(count),
                                rowData = cytof_cluster,
                                colData = cytof_sample)
class(lse)
showClass("leafSummarizedExperiment")
lse

```

The output *lse* is a `leafSummarizedExperiment` object. It has the 
same structure as the `SummarizedExperiment` object. The abundance table of 
clusters is stored as a matrix-like element in `assays`. The cluster information
is stored as `rowData` and the sample information as `colData`. The hierarchical
structure of cell clusters is stored in `metadata`. 

The abundance table in *lse* only provides the count of clusters at tree leaf
level. We are interested to do DA test at different hierarchical level of the
tree,  and aim to find the optimal level in the tree to intepret the association
between the differental abundance of clusters and the phenotypic outcome (here,
CN and healthy). Hence, we also need the abundance of internal nodes that
represent different hierarchical level of the tree and indicate different
resolutions at which data can be viewed. We generate counts of internal nodes by
summing the counts of their descendants, using the `nodeValue` function as shown
below. 

```{r}
tse <- nodeValue(data = lse, fun = sum, message = TRUE)
class(tse)
```

There are more rows in the count table stored in `assays` of *tse* than *lse*. These new generated rows corresponds to the internal nodes of the tree. 
```{r}
dim(assays(lse)[[1]])
dim(assays(tse)[[1]])
```

The `rowData` dimension changes coordinately. 
```{r}
dim(rowData(lse))
dim(rowData(tse))
```
How to access the elements of `leafSummarizedExperiment` and `treeSummarizedExperiment` could be found here (in another vignette "introduction to leafSummarizedExperiment and treeSummarizedExperiment").

The information of a cluster (an internal node) is decided by its descendant
leaves. Here, for example, the column *truth* provides the information whether a cluster is truly differentially abundant. The cluster, which corresponds to an internal node of a tree, would have value `TRUE` in *truth* column if all its descendant clusters have *truth* and have value `NA` in *truth* column if its descendant clusters have different values for *truth*.
```{r}
# select a cluster that corresponds to an internal node of the tree and has TRUE
# in the 'truth' column
sel <- which(rowData(tse)$truth & !linkData(tse)$isLeaf)[1]
rowData(tse)[sel, ]

# find the descendant clusters (nodes) of the selected cluster
desd <- findOS(tree = treeData(tse), ancestor = linkData(tse)$nodeNum[sel], 
               only.Tip = TRUE, return = "number")
# The descendants all have TRUE in the 'truth' column
rowData(tse)[match(desd, linkData(tse)$nodeNum), ]

```


# Differential abundance analysis {#analysis}
## Analysis on a single table

In `treeSummarizedExperiment` object, multiple tables are allowed to store as a list in
the `assays`. Users could choose to perform analysis on one of them or on multiples simultaneously. We start to show you how to do it on a table.

Users are free to choose suitable R packages to run DA test. Here, as an
example, the analysis with `r Biocpkg("edgeR")` is shown. There are two options
to do it.

* Option 1: use functions from `r Biocpkg("edgeR")`. This is more flexible and
allows more customized settings.

* Option 2: use function `runEdgeR` from `r Biocpkg("treeAGG")`. It's a wrapper
using functions from `r Biocpkg("edgeR")`.

### Option 1: Use `r Biocpkg("edgeR")` {#option1}

Extract the count table to do data analysis. To make sure we know which row corresponds to which node of the tree, we need to use `use.nodeLab = TRUE`. It might lead to errors in the tree aggregation step if users forget to set `use.nodeLab = TRUE`.
```{r}
# extract the abundace table
count <- assays(tse, use.nodeLab = TRUE)[[1]]
```

Then, we follow the routine steps of using package `r Biocpkg("edgeR")` as below.
```{r}
# calculate sample size for each sample
# The sample size is the sum of cell counts of clusters on the leaf level of the tree.
tip_tse <- tse[linkData(tse)$isLeaf, ]
tipCount <- assays(tip_tse, use.nodeLab = TRUE)[[1]]
libSize <- apply(tipCount, 2, sum)

# create DGEList
y <- DGEList(counts = count, lib.size = libSize,
             remove.zeros = FALSE)

# calculate normalisation factors
y <- calcNormFactors(object = y, method = "TMM")

# construct design matrix
sample_inf <- colData(tse)
design <- model.matrix(~ subject + group, data = sample_inf)

# estimate dispersion
y <- estimateGLMRobustDisp(y, design = design)

# fit the negative binomial GLMs
fit <- glmFit(y, design = design, prior.count = 0.125)

# run likelihood ratio tests 
# contrast is not specified here, so the last coefficient is tested.
lrt <- glmLRT(fit, contrast = NULL)

# Use Benjamin-Hochberg method to do multiple testing correction
# n is set to Inf below, because we want to have the results of all entities.
out <- topTags(lrt, n = Inf, adjust.method = "BH")$table
head(out)
```
The output *out* has five columns, one of which is the adjusted p-value named
*FDR*. This *FDR* column is required by the tree aggregation step. If users choose other softwares to do analysis, we expect they could finally get results similar to *out* with a column of adjusted p-value and each row representing a node of the tree structure. We could further store the result in the `rowData` of *tse* via a function `updateTSE`.

```{r}
# put *out* in a list. 
outList <- list(assay1 = list(out))
new_tse1 <- updateTSE(result = outList, tse = tse, 
                     use.assays = 1, design = design, contrast = NULL, 
                     fit = fit)
```
The result *out* is changed to a list object *outList* before it is assigned to the argument `result`. The reason to do it could be seen later in the section ?? where analysis on multiple tables with multiple contrasts are preformed. Give the name of the data container, *tse*,  where the results will be stored. Tell the function which tables of `assays` in *tse* have been used to get the analysis result *out* by using `use.assays`. Give the design matrix and contrasts that have been used in the analysis via `design` and `contrast`, and these would be stored in the `metadata` of the new `treeSummarizedExperiment` object *new_tse*. Users could optionally store the result *fit* created before by the `glmFit` function for later use, for example, to quickly get new result when specify a new contrast.

```{r}
rowData(new_tse1)
```
We see that there is a new column called *result_assay1* that stores the result *out*.
```{r}
rowData(new_tse1)$result_assay1
```

If users want to see only the original row data, it could be achieved by specify `internal = FALSE`.
```{r}
rowData(new_tse1, internal = FALSE)
```


### Option 2: Wrapper function

In the package `r Biocpkg("treeAGG")`, we have provided a wrapper function to do
the work performed in the section \@ref(option1) in one step.

```{r}
new_tse2 <- runEdgeR(obj = tse, use.assays = 1, design = NULL, 
                 contrast = NULL, normalize = TRUE, method = "TMM", 
                 adjust.method = "BH")
new_tse2
```
The prepared data *tse* is assigned to `obj` argument. If there are more than
one matrix-like elements in the `assays`, we could use `use.assays` to select
which elements will be used for analysis. Here, the first matrix-like element
will be used as `use.assays = 1`. Users could customize the design matrix and
contrasts via `design` and `contrast`, respectively, and they will be saved in
the `metadata` of the output for later check. If they are not given, the wrapper
function will by default use `colData` to generate a design matrix and test the
last coefficient in the `glmLRT` step.

## Analysis on multiple tables with multiple contrasts

Here, we will show you how to perform analysis simultaneously on multiple tables.

We create a new `treeSummarizedExperiment` object *tseM* with 3 tables in the assay.
It is the same to the *tse* except the part of `assays`.
```{r}
# extract the abundace table
count <- assays(tse, use.nodeLab = TRUE)[[1]]
# new treeSummarizedExperiment with three tables in the assays
tseM <- treeSummarizedExperiment(assays = list(count, (2*count), (3*count) ),
                                 tree = treeData(tse), 
                                 linkData = linkData(tse),
                                 rowData = rowData(tse),
                                 colData = colData(tse))
```

Assume we want to analyze the first and the third tables. This could be done in
one step. We feed *tseM* to the `obj`, tell R to use the first and third tables `use.assays = c(1, 3)`, and specify the design and contrasts via `design` and `contrast`. Then, we get the analysis results updated in the `rowData` of *new_tseM*.
```{r}
new_tseM <- runEdgeR(obj = tseM, use.assays = c(1, 3), design = NULL, 
                 contrast = list(contrast1 = NULL, contrast2 = c(0, 0, 0, 1, -1, 0)),
                 normalize = TRUE, method = "TMM", 
                 adjust.method = "BH")
new_tseM
```

If users want to do some customized settings that are not provided above, they could extract the target tables and follow the work in section \@ref(option1) and finally integrate the results into *tseM* using function `updateTSE` as below. 

```{r}
count1 <- assays(tseM, use.nodeLab = TRUE)[[1]]
count3 <- assays(tseM, use.nodeLab = TRUE)[[3]]


# calculate library size
count1.t <- assays(tseM[linkData(tseM)$isLeaf, ], use.nodeLab = TRUE)[[1]]
count3.t <- assays(tseM[linkData(tseM)$isLeaf, ], use.nodeLab = TRUE)[[3]]
libSize1 <- apply(count1.t, 2, sum)
libSize3 <- apply(count3.t, 2, sum)

# create DGEList
y1 <- DGEList(counts = count1, lib.size = libSize1, remove.zeros = FALSE)
y3 <- DGEList(counts = count3, lib.size = libSize3, remove.zeros = FALSE)

# calculate normalisation factors
y1 <- calcNormFactors(object = y1, method = "TMM")
y3 <- calcNormFactors(object = y3, method = "TMM")

# construct design matrix
sample_M <- colData(tseM)
designM <- model.matrix(~ subject + group, data = sample_M)

# estimate dispersion
y1 <- estimateGLMRobustDisp(y1, design = designM)
y3 <- estimateGLMRobustDisp(y3, design = designM)

# fit the negative binomial GLMs
fit1 <- glmFit(y1, design = designM)
fit3 <- glmFit(y3, design = designM)

# run likelihood ratio tests 
# using different contrasts
lrt1.1 <- glmLRT(fit1, contrast = NULL)
lrt1.2 <- glmLRT(fit1, contrast = c(0, 0, 0, 1, -1, 0))

lrt3.1 <- glmLRT(fit3, contrast = NULL)
lrt3.2 <- glmLRT(fit3, contrast = c(0, 0, 0, 1, -1, 0))

# Use Benjamin-Hochberg method to do multiple testing correction
# n is set to Inf below, because we want to have the results of all entities.
out1.1 <- topTags(lrt1.1, n = Inf, adjust.method = "BH")$table
out1.2 <- topTags(lrt1.2, n = Inf, adjust.method = "BH")$table

out3.1 <- topTags(lrt3.1, n = Inf, adjust.method = "BH")$table
out3.2 <- topTags(lrt3.2, n = Inf, adjust.method = "BH")$table

```

To write the results back to the *tseM*, we could use function `updateTSE`.
```{r}
# put the contrasts used as a list and name the contrasts
contrastList <- list(contrast1 = NULL, contrast2 = c(0, 0, 0, 1, -1, 0))

# put the results obtained as a list
resultList <- list(assay1 = list(contrast1 = out1.1, contrast2 = out1.2), 
                   assay3 = list(contrast1 = out3.1, contrast2 = out3.2))

# write the result back to the tseM
new_tseM2 <- updateTSE(result = resultList, tse = tseM, use.assays = c(1, 3),
                      design = designM, contrast = contrastList, 
                      fit = list(fit1, fit3))
```
Create a list to store the contrasts used in the analysis and name each
contrast. The results are also organized into a list with the following
requirements.

* Results from the same assay table with different contrasts are stored in a
list. They are named according to their contrasts as *contrastList*. 
* Results
from different assay tables are further organized in a list. They are named with
the `assay` followed by the number that the table is in the `assays` of *tseM*

The output *out* has five columns, one of which is the adjusted p-value named
*FDR*. This *FDR* column is required by the tree aggregation step. If users choose other softwares to do analysis, we expect they could finally get results similar to *out* with a column of adjusted p-value and each row representing a node of the tree structure. We could further store the result in the `rowData` of *tse* via a function `updateTSE`.


```{r}
all.equal(new_tseM, new_tseM2)
```

# Tree aggregation {#aggregation}

The tree aggregation could be done in one step by using function `treeAGG`.
```{r}
aggR <- treeAGG(data = new_tseM, sigf.by = "FDR", 
                sigf.limit = 0.05, agg.by = "FDR", 
                message = TRUE)
```
Feed the argument `data` with the output from the previous analysis section
*new_tse*. The column used for tree aggregation is specified by the column name
via `agg.by`, and that for the decision whether the NULL hypothesis at a node
should be rejected is specified by `sigf.by` (or actually, the column stores
adjusted p value). Users could decide the threshold value for the column
`sigf.by` via `sigf.limit`. If the aggregation takes time, we could set `message
= TRUE` to see the running process.
With `topNodes`, the result table from the DA analysis and tree aggregation step
could be printed out. The output *aggR* from previous step is assigned to
`data`. The argument `use.assays = 1` is to show only results obtained from the
first table stored in `assays`. We could further specify how the rows should be
ordered via `sort.by` and `decreasing`. If some columns in `linkData` or
`rowData` are also needed, they could be extracted out simutaneously via
`col.rowData` and `col.linkData`, respectively.
```{r}
tabL <- topNodes(data = aggR, sort.by = "FDR", decreasing = FALSE,
                 use.assays = 1, col.rowData = NULL, 
                 col.linkData = "nodeNum")
```
Here, *tabL* is simply a list and users could extract any subelements by the
operations on the `list` class. Below, we will display the result gained with
the contrast NULL.
```{r}
tabR <- tabL$result_assay1$contrast1
```
The tree aggregation adds a column named *aggKeep* to each result table. This
column include values `TRUE` and `FALSE`. Those rows with value `TRUE`
corresponds to nodes that are finally selected as the estimated optimal level to
interpret the differential abundance pattern on the tree.

# Result visualisation

The information of true differentially abundant is stored in the column *truth*
of the `rowData`. We subset the `treeSummarizedExperiment` object *aggR* to keep
only clusters that are truly differentially abundant between patient and CN
samples, and then use function `signalNode` to find nodes that could describe
the differential abundance pattern of the tree using as few nodes as possible
while avoid false discoveries. In other words, `signalNode` gives the optimal
level to interpret the differential abundance pattern.
```{r}
# Nodes that are truely differentially abundant
diffR <- aggR[rowData(aggR)$truth %in% TRUE, ]
# True signal (the optimal level to describe the differential abundant pattern
# in the tree)
trueLoc <- signalNode(tree = treeData(diffR), node = linkData(diffR)$nodeNum)
```

The estimated optimal level to interpret the differential abundance pattern from
`r Biocpkg("treeAGG")` is as below. Here, we extract the node number (`nodeNum`)
instead of the node label because, depends on how people generate the tree, internal nodes might not have labels assigned to them in some trees.
```{r}
# Nodes that are estimated to be differentially abundant
estLoc <- tabR$nodeNum[tabR$aggKeep]
```
If users are interested to the node label instead of the node number,
`transNode` available in our package could simply do the transformaton between
the two. Check the example in the help page `?transNode` to see more details.

```{r}
# transform the node number to node label
# NA obtained, because in the tree structure, no label is assigned for this internal node.
transNode(tree = treeData(aggR), input = estLoc, use.original = TRUE)
```

To compare the estimated with the truth, we use `treePlot` to generate a tree
figure. The function `treePlot` is created based on `r
Biocpkg("ggtree")`[@Yu2017] and `r CRANpkg("ggplot2")`[@Wickham2016]. The
branches with blue edges are truly differentially abundant. The results obtained
from the minP algorithm are shown as orange points. Nodes labelled with orange
points are the suggested optimal level at which to interpret the signal.
```{r fig.height= 2}
p <- treePlot(tree = treeData(diffR) ,  
              branch = trueLoc,
              point = estLoc,
              zoomNode = c(trueLoc, estLoc),
              layout = "circular")
p
```




# Reference

